
# ICLR 2020 yann lecun
在演講一開始 Facebook AI 研究院的 Yann Lecun 說到：「自督導式學習 (Self-supervised Learning) 是未來的人工智慧與機器學習」。同時並點出人類和動物是如何學習？以及為什麼能夠在非監督式的情況下會學習的如此快速？首先下面這個圖表能夠快速了解在嬰兒時期，每一位寶寶的洞察力與生產力的時間點。包括物體恆存、穩定平衡、直覺思維...等。這些都是由剛出生的嬰兒透過觀察所學習到的，並且以這種方式探索與認識世界。

![](https://i.imgur.com/9ZU3exa.png)

如果有種機器學習能夠像嬰兒這樣透過觀察能力來學習認知這個世界，想必對於監督式學習所要的標籤依賴性就大幅減少了。以 Yann Lecun 的觀點來看，人工智能的下一波革命並不是監督式和強化學習。而重點在於特徵表達學習 (Representation Learning)。

> Jitendra Malik: "Labels are the opium of the machine learning researcher"

## 深度學習三大挑戰
首先就以大家最常見的深度學習來說，幾乎每一種任務都必須準備好資料以及相對應的答案(標籤)，機器才能夠從資料當中進行學習。然而當現實生活中資料取得不易狀況下，監督式學習將會面臨第一個困難與挑戰。第二點是現今大多數主流的深度學習框架非神經網路架構莫屬，然而在這複雜的黑盒子當中透過基於梯度的學習 (Gradient-Based Learning) 難以說明人類的推理與決策方式相提並論。因此我們希望訓練出來的模型必須要有感知認知的能力。第三個是如何學習一連串複雜的任務？通常我們會將一個複雜任務分解成很多個子任務，並將組合起來成為強大的網路架構並應用在影像、語音、文字...等。但是該如何直接地去學習這複雜的階層是架構任務還是一個很大的挑戰。而自督導式學習主要還是專注在解決第一點，如何透過截取一個好的表徵(Representation)進行主任務的預測。

- 在資料標籤少的狀況下進行模型訓練
- 學習推理與具有認知能力
- 如何學習複雜的任務

## Self-Supervised Learning = Filling in the Blanks
Yann Lecun 解釋自督導式學習就是學習如何去填空。假裝有一部分你不知道並試著學習如何預測去填補未知的事物，例如從過去經驗去預測未來，或是從觀察到的事物預測未知的內容。

![](https://i.imgur.com/iZel3Ol.png)

一般的神經網路是鎖住訓練好的網路參數進行推論與計算，丟入 x 輸出一個 y。若當今天的任務是一個影像要預測未來多個時間點的影像動作。網路架構就會變得複雜，該如何去解決這類問題。


